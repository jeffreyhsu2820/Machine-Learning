# NTU Machine Learning  
109-2 Machine Learning   
由李宏毅教授、吳沛遠教授和林宗男教授共同合授。吳沛遠教授負責授課與作業規劃。   
### HW1 Linear Regression
Competition: https://www.kaggle.com/competitions/ml2020fall-hw1  
Data: Data was downloaded from the Air Quality Monitoring Network of the Environmental Protection Agency of the Executive Yuan.  
Goals: Handcraft the Linear Regression Model to predict the value of PM2.5.  
Apply Linear Regression Model with Gradiend descent without using the packages.   
- [x] Simple baseline (linear regression with adagrad) 
- [x] Strong baseline (linear regression with adagrad) 
### HW2 Logistic Regression
Competition: https://www.kaggle.com/competitions/ml2020fall-hw2   
Data: Census-Income Dataset from https://archive.ics.uci.edu/ml/datasets/Adult  
Goals: Handcraft the Logistic Regression Model with Gradient Descent and probabilistic generative model to recognize the income of an individual exceeds $50000 or not.  
### HW3 CNN
Competition: https://www.kaggle.com/competitions/ml2020fall-hw3  
Data: Facial Expression Recognition 2013 Dataset
Goals: Implement CNN model.
### HW4 Text Sentiment Classification (RNN)  
Competition: https://www.kaggle.com/competitions/ml2020fall-hw5
Data:  
Training data: 190,000 labeled data  
Test data: 10,000 tweets  
Goals: Use RNN/ BOW+DNN to predict whether a tweet is a malicious tweet.  
### HW5 Image Clustering
Competition: https://www.kaggle.com/competitions/ml2020fall-hw5-1  
Data: 9,000 unlabeled images with 32x32x3 pixels are provided   
Goals: Determine whether the given pictures are landscapes or not. (Practice Autoencoder and clustering methods.)   
### Final Project
Competition: https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques
Data: With 79 explanatory variables describing every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.  
Goals: Creative feature engineering and regression techniques   
